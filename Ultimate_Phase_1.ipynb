{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e723fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import csv\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d098151",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Service:\n",
    "    def __init__(\n",
    "        self,\n",
    "        service_id, \n",
    "        rake_num,\n",
    "        start_station,\n",
    "        start_time,\n",
    "        end_station,\n",
    "        end_time,\n",
    "        direction,\n",
    "        service_time=0,\n",
    "        same_jurisdiction=None,\n",
    "        step_back_rake=None,\n",
    "        step_back_location=None,\n",
    "        merged_rake_num1=None,\n",
    "        merged_rake_num2=None\n",
    "    ):\n",
    "        self.service_id = str(service_id)\n",
    "        self.rake_num = rake_num\n",
    "        self.start_station = start_station\n",
    "        self.start_time = start_time\n",
    "        self.end_station = end_station\n",
    "        self.end_time = end_time\n",
    "        self.direction = direction\n",
    "        self.service_time = int(service_time) if service_time else 0\n",
    "        self.same_jurisdiction = same_jurisdiction\n",
    "        self.step_back_rake = step_back_rake\n",
    "        self.step_back_location = step_back_location\n",
    "        self.merged_rake_num1 = merged_rake_num1\n",
    "        self.merged_rake_num2 = merged_rake_num2\n",
    "\n",
    "\n",
    "def load_services(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    services = []\n",
    "    for _, row in df.iterrows():\n",
    "        s = Service(\n",
    "            service_id=row.get(\"Service\"),   \n",
    "            rake_num=row.get(\"Rake Num\"),\n",
    "            start_station=get_base_station_name(row.get(\"Start Station\")),\n",
    "            start_time=parse_time_to_minutes(row.get(\"Start Time\")),\n",
    "            end_station=get_base_station_name(row.get(\"End Station\")),\n",
    "            end_time=parse_time_to_minutes(row.get(\"End Time\")),\n",
    "            direction=row.get(\"Direction\"),\n",
    "            service_time=int(row[\"service time\"]) if \"service time\" in row and pd.notna(row[\"service time\"]) else 0,\n",
    "            same_jurisdiction=row[\"Same Jurisdiction\"] if \"Same Jurisdiction\" in row else None,\n",
    "            step_back_rake=row[\"Step Back Rake\"] if \"Step Back Rake\" in row else None,\n",
    "            step_back_location=row[\"Step Back Location\"] if \"Step Back Location\" in row else None,\n",
    "            merged_rake_num1=row[\"mergedRakeNum1\"] if \"mergedRakeNum1\" in row else None,\n",
    "            merged_rake_num2=row[\"mergedRakeNum2\"] if \"mergedRakeNum2\" in row else None,\n",
    "        )\n",
    "        services.append(s)\n",
    "    return services\n",
    "\n",
    "\n",
    "#----------------------------------# Adding Dummy Nodes\n",
    "# Dummy start node\n",
    "start_service = Service(\n",
    "    service_id=\"S\",\n",
    "    rake_num=None,\n",
    "    start_station=None,\n",
    "    start_time=None,\n",
    "    end_station=None,\n",
    "    end_time=None,\n",
    "    direction=None,\n",
    "    service_time=0,\n",
    "    same_jurisdiction=None,\n",
    "    step_back_rake=None,\n",
    "    step_back_location=None,\n",
    "    merged_rake_num1=None,\n",
    "    merged_rake_num2=None\n",
    ")\n",
    "\n",
    "# Dummy end node\n",
    "end_service = Service(\n",
    "    service_id=\"T\",\n",
    "    rake_num=None,\n",
    "    start_station=None,\n",
    "    start_time=None,\n",
    "    end_station=None,\n",
    "    end_time=None,\n",
    "    direction=None,\n",
    "    service_time=0,\n",
    "    same_jurisdiction=None,\n",
    "    step_back_rake=None,\n",
    "    step_back_location=None,\n",
    "    merged_rake_num1=None,\n",
    "    merged_rake_num2=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe64768a",
   "metadata": {},
   "source": [
    "## Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c886d81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Configuration ===\n",
    "#TIMETABLE_FILE = \"C:/Users/srupe/Downloads/crew/mainLoop_aadesh.csv\"\n",
    "MIN_RAKE_GAP_MINUTES = 30   # Minimum required gap between different rakes\n",
    "ALLOWED_RAKE_CHANGE_STATIONS = {\"KKDA\", \"PVGW\"}  # Allowed rake-change stations\n",
    "MAX_CONNECTION_GAP_MINUTES = 120   # Maximum allowed gap between services\n",
    "\n",
    "BREAK_STATIONS = {\"KKDA\", \"PVGW\"}  # Breaks allowed only here\n",
    "CUMULATIVE_BREAKS_DURATION = 120    # cumulative breaks should be less than CUMULATIVE_BREAKS_DURATIONS min\n",
    "SHORT_BREAK = 30     # short break duration\n",
    "LONG_BREAK =  50     # Long break duration\n",
    "DUTY_TIME_LIMIT = 445 # Noraml duty duration\n",
    "MORN_EVEN_DUTY_TIME_LIMIT = 405  # morning and evening duty time duration\n",
    "MORNING_SHIFT_CUTOFF = 360     # 360 -> 6:00 AM\n",
    "EVENING_SHIFT_CUTOFF = 1410     # 1410 -> 23:30 PM\n",
    "CONTINUOUS_DRIVE_LIMIT = 180   # continuous driving without a break greater than 30 mins in it.\n",
    "DRIVING_TIME_LIMIT =360        # Actual driving time(Mins) it have gaps< SHORT_BREAKS also counted in it\n",
    "\n",
    "\n",
    "# === Jurisdiction Buckets ===\n",
    "jurisdiction_dict = {\n",
    "    1: {'MKPR','MKPR UP','MKPR DN','SAKP','DDSC','DDSC DN PF','DDSC SDG','DDSC SDG STABLE (DAY)','DDSC DN',\n",
    "        'DDSC SDG','PVGW','PVGW UP','PVGW DN','MKPD','MKPD','SAKP 3RD','SAKP 3RD PF','MKPR DN SDG','MKPR DN PF','DDSC DN SDG'},\n",
    "    2: {'MUPR DN SDG STABLE (DAY)','MUPR 4TH SDG STABLE (DAY)','MUPR 3RD SDG STABLE','SVVR','SVVR DN','MUPR',\n",
    "        'MUPR DN','MUPR 4TH','MUPR 3RD SDG','KKDA DN','KKDA UP','IPE','IPE 3RD PF','IPE 3RD','VND','VND (M)',\n",
    "        'MVPO','MVPO DN','NZM','NIZM','KKDA','MUPR DN SDG','MVPO DN PF','SVVR DN PF','MUPR 3RD SDG','MUPR 4TH PF',\n",
    "        'MUPR 4TH SDG','MUPR DN PF','MUPR DN SDG','MUPR DN SDG'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2b4e159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Utility Functions ===\n",
    "def parse_time_to_minutes(t: str):\n",
    "    \"\"\"\n",
    "    Converts a time string 'HH:MM' or 'HH:MM:SS' into minutes since midnight.\n",
    "    Supports hours >= 24 (e.g., 24:05 → 1445 minutes, 25:07 → 1507 minutes)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        t = t.strip()\n",
    "        # Split HH:MM or HH:MM:SS\n",
    "        parts = t.split(\":\")\n",
    "        hours = int(parts[0])\n",
    "        minutes = int(parts[1])\n",
    "        return hours * 60 + minutes\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_base_station_name(station: str):\n",
    "    \"\"\"Extracts the base station name (first word) in uppercase.\"\"\"\n",
    "    if not station:\n",
    "        return None\n",
    "    return station.strip().split()[0].upper()\n",
    "\n",
    "\n",
    "def rake_feasible_connection(s1, s2):\n",
    "    \"\"\"\n",
    "    Checks if a connection between two services is feasible.\n",
    "    - Must be same base station.\n",
    "    - 0 <= (start - end) <= MAX_CONNECTION_GAP_MINUTES\n",
    "    - If rake is same: allow directly.\n",
    "    - If rake is different: allowed only at ALLOWED_RAKE_CHANGE_STATIONS \n",
    "      and gap >= MIN_RAKE_GAP_MINUTES.\n",
    "    \"\"\"\n",
    "\n",
    "    # Skip if stations or times are missing\n",
    "    if not s1.end_station or not s2.start_station or s1.end_time is None or s2.start_time is None:\n",
    "        return False\n",
    "    \n",
    "    # Handle dummy start/end services\n",
    "    if not s1.end_station or not s2.start_station:\n",
    "        return False\n",
    "\n",
    "    if s1.end_station != s2.start_station:\n",
    "        return False\n",
    "\n",
    "    gap = s2.start_time - s1.end_time\n",
    "\n",
    "    # Must be non-negative and within max connection window\n",
    "    if gap < 0 or gap > MAX_CONNECTION_GAP_MINUTES:\n",
    "        return False\n",
    "\n",
    "    if s1.rake_num == s2.rake_num:\n",
    "        # Same rake: gap condition is already checked\n",
    "        return True\n",
    "    else:\n",
    "        # Rake change allowed only at certain stations with min gap\n",
    "        return (s1.end_station in ALLOWED_RAKE_CHANGE_STATIONS) and (gap >= MIN_RAKE_GAP_MINUTES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9042a46b",
   "metadata": {},
   "source": [
    "## Graph building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3623a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(services_list, start_service, end_service):\n",
    "    \"\"\"\n",
    "    Build a directed graph from Service objects.\n",
    "    All nodes are Service objects (including start and end dummies).\n",
    "    \"\"\"\n",
    "\n",
    "    services_list = [s for s in services_list if s.start_time is not None and s.end_time is not None]\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Add nodes (store Service object directly as key)\n",
    "    for s in services_list:\n",
    "        G.add_node(s.service_id, data=s)\n",
    "\n",
    "    # Add start/end dummy nodes\n",
    "    G.add_node(start_service.service_id, data=start_service)\n",
    "    G.add_node(end_service.service_id, data=end_service)\n",
    "\n",
    "    # Connect source to all services\n",
    "    for s in services_list:\n",
    "        G.add_edge(start_service.service_id, s.service_id, color=\"black\")\n",
    "\n",
    "    # Feasible service_id-to-service_id connections\n",
    "    for i, s1 in enumerate(services_list):\n",
    "        for j, s2 in enumerate(services_list):\n",
    "            if i == j:\n",
    "                continue\n",
    "            if rake_feasible_connection(s1, s2):\n",
    "                #edge_color = \"red\" if s1.rake_num != s2.rake_num else \"gray\"\n",
    "                G.add_edge(s1.service_id, s2.service_id)\n",
    "\n",
    "    # Connect all services to sink\n",
    "    for s in services_list:\n",
    "        G.add_edge(s.service_id, end_service.service_id, color=\"black\")\n",
    "\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af5e26d",
   "metadata": {},
   "source": [
    "## Checking Current path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1987b9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_path_acceptable(\n",
    "    path, end_service,\n",
    "    total_driving_time, DRIVING_TIME_LIMIT,\n",
    "    DUTY_TIME_LIMIT\n",
    "):\n",
    "    \"\"\"\n",
    "    Checks whether a partial path is acceptable:\n",
    "    - Driving time limit\n",
    "    - Duty time limit\n",
    "    - Continuous driving CONTINUOUS_DRIVE_LIMIT-min rule\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # -----------------------------\n",
    "    # Condition 1: Driving time limit\n",
    "    # -----------------------------\n",
    "    if total_driving_time > DRIVING_TIME_LIMIT:\n",
    "        return False\n",
    "\n",
    "    # -----------------------------\n",
    "    # Condition 2: Duty time limit\n",
    "    # -----------------------------\n",
    "    first_service_start_time = path[1].start_time  # skip dummy SOURCE\n",
    "\n",
    "    if path[-1] == end_service:\n",
    "        last_service = path[-2]  # path ended with sink dummy\n",
    "    else:\n",
    "        last_service = path[-1]\n",
    "\n",
    "    last_service_end_time = last_service.end_time\n",
    "    total_duty_time = last_service_end_time - first_service_start_time\n",
    "\n",
    "    # Morning/evening tighter limit\n",
    "    if first_service_start_time < MORNING_SHIFT_CUTOFF or first_service_start_time > EVENING_SHIFT_CUTOFF:\n",
    "        effective_duty_limit = MORN_EVEN_DUTY_TIME_LIMIT\n",
    "    else:\n",
    "        effective_duty_limit = DUTY_TIME_LIMIT      # usually 445\n",
    "\n",
    "    if total_duty_time > effective_duty_limit:\n",
    "        return False\n",
    "\n",
    "    # -----------------------------\n",
    "    # Condition 3: Continuous driving CONTINUOUS_DRIVE_LIMIT rule\n",
    "    # -----------------------------\n",
    "    continuous_drive = 0\n",
    "    # skip dummy SOURCE and SINK\n",
    "    end_index = len(path) - 1 if path[-1] == end_service else len(path)\n",
    "\n",
    "\n",
    "    for i in range(1, end_index):\n",
    "        current_service = path[i]\n",
    "        service_time = current_service.service_time or 0\n",
    "        continuous_drive += service_time\n",
    "    \n",
    "        # Add gap to next service if it exists\n",
    "        if i < end_index - 1:\n",
    "            next_service = path[i + 1]\n",
    "            gap_btw_service = next_service.start_time - current_service.end_time\n",
    "    \n",
    "            if gap_btw_service < SHORT_BREAK:\n",
    "                continuous_drive += gap_btw_service\n",
    "            elif gap_btw_service >= SHORT_BREAK:\n",
    "                continuous_drive = 0\n",
    "    \n",
    "        # Rule 1: cannot exceed continuous drive limit\n",
    "        if continuous_drive > CONTINUOUS_DRIVE_LIMIT:\n",
    "            return False\n",
    "\n",
    "    # -----------------------------\n",
    "    # All conditions passed\n",
    "    # -----------------------------\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b298a855",
   "metadata": {},
   "source": [
    "## Checking Final Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d91c4b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def get_jurisdiction_groups(station):\n",
    "    \"\"\"\n",
    "    Return the set of jurisdiction groups a station belongs to.\n",
    "\n",
    "    CHANGE 1: Add caching (lru_cache) so repeated calls with the same station\n",
    "    are very cheap. We return a frozenset (immutable) so the cached object is\n",
    "    stable and safe to use with set operations like isdisjoint.\n",
    "    \"\"\"\n",
    "    # build frozenset from global jurisdiction_dict \n",
    "    return frozenset(\n",
    "        Jurisdiction_group_id\n",
    "        for Jurisdiction_group_id, stations in jurisdiction_dict.items()\n",
    "        if station in stations\n",
    "    )\n",
    "\n",
    "\n",
    "def is_final_path_valid(path):\n",
    "    \"\"\"\n",
    "    Check if a completed path ending at end_service is valid based on:\n",
    "    1. Jurisdiction overlap between first and last duty.\n",
    "    2. Required break conditions.\n",
    "    \"\"\"\n",
    "\n",
    "    # === Jurisdiction check ===\n",
    "    start_station_first_duty = path[1].start_station\n",
    "    end_station_last_duty = path[-2].end_station\n",
    "\n",
    "    start_groups = get_jurisdiction_groups(start_station_first_duty)\n",
    "    end_groups = get_jurisdiction_groups(end_station_last_duty)\n",
    "\n",
    "    # Short-circuit early: if no overlap in jurisdiction groups => invalid path.\n",
    "    # This avoids running the more expensive break logic when jurisdiction fails.\n",
    "    if start_groups.isdisjoint(end_groups):\n",
    "        return False\n",
    "\n",
    "    # Pass computed start_groups into has_required_breaks to\n",
    "    # avoid recomputing the same group inside that function.\n",
    "    if not has_required_breaks(path, start_jurisdictions=start_groups):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def has_required_breaks(path, start_jurisdictions=None):\n",
    "    \"\"\"\n",
    "    Check break conditions:\n",
    "    Case 1: Only one break >=50min (and total < CUMULATIVE_BREAKS_DURATION).\n",
    "    Case 2: Multiple breaks:\n",
    "        - If there a 30min break, at least one >=50min break must also exist.\n",
    "        - Two or more >=50min breaks are allowed.\n",
    "        - In all cases, total < CUMULATIVE_BREAKS_DURATION.\n",
    "    Additional:\n",
    "    - At least one break must lie within the jurisdiction of the first duty's start station.\n",
    "\n",
    "    CHANGE 2: Accept `start_jurisdictions` as an optional argument. If provided,\n",
    "    we reuse it instead of calling get_jurisdiction_groups(path[1].start_station).\n",
    "    \"\"\"\n",
    "\n",
    "    if len(path) < 6:\n",
    "        return False  # skip very short paths\n",
    "\n",
    "    # Use passed-in start_jurisdictions if available (avoids recomputation).\n",
    "    if start_jurisdictions is None:\n",
    "        start_station_first_duty = path[1].start_station\n",
    "        start_jurisdictions = get_jurisdiction_groups(start_station_first_duty)\n",
    "\n",
    "    # Extract times\n",
    "    start_times = [s.start_time for s in path[1:-1]]\n",
    "    end_times = [s.end_time for s in path[1:-1]]\n",
    "\n",
    "    gaps = [\n",
    "        start_times[i + 1] - end_times[i]\n",
    "        for i in range(len(start_times) - 1)\n",
    "    ]\n",
    "\n",
    "    breaks = []\n",
    "    has_break_in_same_jurisdiction = False\n",
    "\n",
    "    for i, break_gap in enumerate(gaps):\n",
    "        station = path[1 + i].end_station  # station where break occurs\n",
    "\n",
    "        # Only consider allowed break stations and minimal break_gap\n",
    "        if station in BREAK_STATIONS and break_gap >= SHORT_BREAK:\n",
    "            breaks.append(break_gap)\n",
    "\n",
    "            break_jurisdictions = get_jurisdiction_groups(station)\n",
    "            if not start_jurisdictions.isdisjoint(break_jurisdictions):\n",
    "                has_break_in_same_jurisdiction = True\n",
    "\n",
    "    if not breaks:\n",
    "        return False\n",
    "\n",
    "    # Ensure at least one break is in same jurisdiction\n",
    "    if not has_break_in_same_jurisdiction:\n",
    "        return False\n",
    "\n",
    "    total_break = sum(breaks)\n",
    "    if total_break > CUMULATIVE_BREAKS_DURATION:                       # changed here\n",
    "        return False\n",
    "\n",
    "    has_SHORT_BREAK = any(SHORT_BREAK <= b < LONG_BREAK for b in breaks)\n",
    "    has_LONG_BREAK = any(b >= LONG_BREAK for b in breaks)\n",
    "\n",
    "    # Case 1: single break\n",
    "    if len(breaks) == 1:\n",
    "        return has_LONG_BREAK\n",
    "\n",
    "    # Case 2: multiple breaks\n",
    "    if has_SHORT_BREAK and not has_LONG_BREAK:\n",
    "        return False  # shorts without a long break not allowed\n",
    "\n",
    "    # Valid if (short + long) OR (multiple longs)\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83191d91",
   "metadata": {},
   "source": [
    "## Stack based DFS and saving feasible duties to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d6fc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_based_all_paths(\n",
    "    G, start_service, end_service,\n",
    "    DRIVING_TIME_LIMIT, DUTY_TIME_LIMIT,\n",
    "    max_paths=int,\n",
    "    output_csv=\"valid_paths_using_Network_1010_1.csv\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Enumerates all feasible paths using stack-based DFS.\n",
    "    Saves valid paths (formatted) into a CSV file.\n",
    "    \"\"\"\n",
    "    stack = [(start_service, [start_service], 0)]  # node, path_so_far, driving time\n",
    "    #n = 0\n",
    "\n",
    "    with open(output_csv, mode='w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "\n",
    "        while stack:\n",
    "            # if n >= max_paths:\n",
    "            #     break\n",
    "\n",
    "            current_service, path, total_driving_time = stack.pop()\n",
    "\n",
    "            for neighbor_id in G.successors(current_service.service_id):\n",
    "                neighbor = G.nodes[neighbor_id][\"data\"]\n",
    "                service_time = neighbor.service_time or 0\n",
    "\n",
    "                # Calculate gap \n",
    "                last_service = path[-1]\n",
    "                if neighbor.start_time is not None and last_service.end_time is not None:\n",
    "                    gap = neighbor.start_time - last_service.end_time\n",
    "                else:\n",
    "                    gap = 0\n",
    "\n",
    "                new_total_driving_time = total_driving_time + service_time\n",
    "                if gap < SHORT_BREAK:                                             # changed here <=\n",
    "                    new_total_driving_time += gap\n",
    "\n",
    "                new_path = path + [neighbor]\n",
    "\n",
    "                if is_path_acceptable(\n",
    "                    new_path, end_service,\n",
    "                    new_total_driving_time, DRIVING_TIME_LIMIT,\n",
    "                    DUTY_TIME_LIMIT\n",
    "                ):\n",
    "                    if neighbor.service_id == end_service.service_id:\n",
    "                        if is_final_path_valid(new_path):\n",
    "                            #n += 1\n",
    "\n",
    "                            # Extract middle services (exclude S and T)\n",
    "                            middle_services = [s.service_id for s in new_path[1:-1]]\n",
    "\n",
    "                            # Write as separate columns (no quotes)\n",
    "                            writer.writerow(middle_services)\n",
    "\n",
    "                            #print(\",\".join(map(str, middle_services)))\n",
    "\n",
    "                    else:\n",
    "                        stack.append((neighbor, new_path, new_total_driving_time))\n",
    "\n",
    "    print(f\"Total valid paths found: {n}\")\n",
    "    return n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6372edf5",
   "metadata": {},
   "source": [
    "## Main Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d806dd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 944 services in 0.193 seconds\n",
      "Built graph with 946 nodes and 23555 edges in 0.498 seconds\n",
      "Total valid paths found: 10000\n",
      "Found 10000 valid paths in 0.625 seconds\n",
      "[Total Time] 1.316 seconds\n"
     ]
    }
   ],
   "source": [
    "# Start total timer\n",
    "total_start_time = time.time()\n",
    "\n",
    "# ================================\n",
    "#  Load CSV services\n",
    "# ================================\n",
    "start_time = time.time()\n",
    "TIMETABLE_FILE = \"C:/Users/srupe/Desktop/MTP/crew/mainLoop_aadesh.csv\"\n",
    "services = load_services(TIMETABLE_FILE)\n",
    "end_time = time.time()\n",
    "print(f\"Loaded {len(services)} services in {end_time - start_time:.3f} seconds\")\n",
    "\n",
    "# ================================\n",
    "# Build graph with Service objects\n",
    "# ================================\n",
    "start_time = time.time()\n",
    "G = build_graph(services, start_service, end_service)\n",
    "end_time = time.time()\n",
    "print(f\"Built graph with {len(G.nodes)} nodes and {len(G.edges)} edges in {end_time - start_time:.3f} seconds\")\n",
    "\n",
    "# ================================\n",
    "# Call stack-based path finder\n",
    "# ================================\n",
    "start_time = time.time()\n",
    "valid_paths_count = stack_based_all_paths(\n",
    "    G,\n",
    "    start_service=start_service,\n",
    "    end_service=end_service,\n",
    "    DRIVING_TIME_LIMIT=360,\n",
    "    DUTY_TIME_LIMIT=445,\n",
    "    max_paths=10000\n",
    ")\n",
    "end_time = time.time()\n",
    "print(f\"Found {valid_paths_count} valid paths in {end_time - start_time:.3f} seconds\")\n",
    "\n",
    "# ================================\n",
    "# Total time\n",
    "# ================================\n",
    "total_end_time = time.time()\n",
    "print(f\"[Total Time] {total_end_time - total_start_time:.3f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
